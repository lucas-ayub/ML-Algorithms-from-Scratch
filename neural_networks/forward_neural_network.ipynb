{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(z, function):\n",
    "    if function == 'relu':\n",
    "        return np.maximum(0, z)\n",
    "    elif function == 'sigmoid':\n",
    "        z = np.clip(z, -500, 500)  # Handle overflow\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    else:\n",
    "        raise ValueError(f\"unknown\")\n",
    "\n",
    "def gradient_of_activation(z, function):\n",
    "    if function == 'relu':\n",
    "        return np.where(z > 0, 1, 0)  \n",
    "    elif function == 'sigmoid':\n",
    "        sig = 1 / (1 + np.exp(-np.clip(z, -500, 500))) # Handle overflow\n",
    "        return sig * (1 - sig)\n",
    "    else:\n",
    "        raise ValueError(f\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__ (self, activation_function, num_neurons, num_neurons_in_previous_layer):\n",
    "        self.weights = 0.01 * np.random.randn(num_neurons, num_neurons_in_previous_layer)\n",
    "        self.bias = np.zeros(num_neurons)\n",
    "        self.activation_function = activation_function\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_neurons_in_previous_layer = num_neurons_in_previous_layer\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Z = self.weights @ X + self.bias\n",
    "        A = activation_function(Z, self.activation_function)\n",
    "        return A\n",
    "    \n",
    "    def update_weights(self, weights, bias):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__ (self, layers, learning_rate):\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    \n",
    "    def optimize(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        A = X\n",
    "        for layer in self.layers:\n",
    "            A = layer.forward(A)\n",
    "        Y_hat = A\n",
    "        return Y_hat\n",
    "    \n",
    "    def fit(self, X, y, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(X)\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                mini_batch_X = X[i:i + batch_size]\n",
    "                mini_batch_y = y[i:i + batch_size]\n",
    "                self.optimize(mini_batch_X, mini_batch_y)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
