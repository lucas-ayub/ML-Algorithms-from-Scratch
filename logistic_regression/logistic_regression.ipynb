{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Implementation of logistic regression from scratch\n",
    "\n",
    "Dataset used available on: https://www.kaggle.com/datasets/merishnasuwal/breast-cancer-prediction-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid function.\n",
    "\n",
    "    :param z: The input value or array.\n",
    "    :return: The sigmoid of the input.\n",
    "    :rtype: float or np.ndarray\n",
    "    \"\"\"\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_loss(y, y_hat):\n",
    "    \"\"\"\n",
    "    Computes the log loss (cross-entropy loss) for binary classification.\n",
    "\n",
    "    :param y: The true label.\n",
    "    :param y_hat: The predicted probability.\n",
    "    :return: The log loss.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15\n",
    "    y_hat = np.clip(y_hat, epsilon, 1 - epsilon)\n",
    "    return -(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Represents a logistic regression model for binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, epochs, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the logistic regression model.\n",
    "\n",
    "        :param X: The feature matrix (training data).\n",
    "        :type X: np.ndarray\n",
    "        :param y: The label vector (training labels).\n",
    "        :type y: np.ndarray\n",
    "        :param epochs: The number of training epochs.\n",
    "        :type epochs: int\n",
    "        :param learning_rate: The learning rate for gradient descent.\n",
    "        :type learning_rate: float\n",
    "        \"\"\"\n",
    "        self.num_data = X.shape[0]\n",
    "        self.num_features = X.shape[1]\n",
    "        self.weights = np.random.randn(self.num_features) * 0.001\n",
    "        self.bias = 0.0\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def compute_accuracy(self):\n",
    "        \"\"\"\n",
    "        Computes the accuracy of the model on the training data.\n",
    "\n",
    "        :return: The accuracy of the model.\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        for i in range(self.num_data):\n",
    "            x_i = self.X[i]\n",
    "            y_i = self.y[i]\n",
    "            y_hat = self.classify(x_i)\n",
    "            if y_hat == y_i:\n",
    "                correct += 1\n",
    "        return correct / self.num_data\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        \"\"\"\n",
    "        Computes the average log loss over the training data.\n",
    "\n",
    "        :return: The average log loss.\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        for i in range(self.num_data):\n",
    "            x_i = self.X[i]\n",
    "            y_i = self.y[i]\n",
    "            z_i = np.dot(self.weights, x_i) + self.bias\n",
    "            y_hat = sigmoid(z_i)\n",
    "            loss += log_loss(y_i, y_hat)\n",
    "        return loss / self.num_data\n",
    "        \n",
    "    def calculate_gradients(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradients of the loss function with respect to the model parameters.\n",
    "\n",
    "        :return: The gradients for the weights and bias.\n",
    "        :rtype: tuple(np.ndarray, float)\n",
    "        \"\"\"\n",
    "        grad_w = np.zeros(self.num_features)\n",
    "        grad_b = 0\n",
    "        for i in range(self.num_data):\n",
    "            x_i = self.X[i]\n",
    "            y_i = self.y[i]\n",
    "            z_i = np.dot(self.weights, x_i) + self.bias\n",
    "            diff = sigmoid(z_i) - y_i\n",
    "            grad_w += diff * x_i\n",
    "            grad_b += diff\n",
    "        grad_w, grad_b = grad_w / self.num_data, grad_b / self.num_data\n",
    "        return grad_w, grad_b\n",
    "        \n",
    "    def update_weights(self):\n",
    "        \"\"\"\n",
    "        Updates the model parameters (weights and bias) using gradient descent.\n",
    "        \"\"\"\n",
    "        grad_w, grad_b = self.calculate_gradients()\n",
    "        self.weights -= self.learning_rate * grad_w\n",
    "        self.bias -= self.learning_rate * grad_b\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the probability of the positive class for the given input data.\n",
    "\n",
    "        :param X: The input feature matrix.\n",
    "        :type X: np.ndarray\n",
    "        :return: The predicted probabilities for the positive class.\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        z = np.dot(self.weights, X) + self.bias\n",
    "        y_hat = sigmoid(z)\n",
    "        return y_hat\n",
    "    \n",
    "    def classify(self, X, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Classifies the input data into binary labels based on the given threshold.\n",
    "\n",
    "        :param X: The input feature matrix.\n",
    "        :type X: np.ndarray\n",
    "        :param threshold: The threshold for classification.\n",
    "        :type threshold: float\n",
    "        :return: The predicted binary label (0 or 1).\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        y_hat = self.predict(X)\n",
    "        return int(y_hat > threshold) \n",
    "      \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the logistic regression model using gradient descent for a specified number of epochs.\n",
    "        \"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            self.update_weights()\n",
    "            loss = self.compute_loss()\n",
    "            accuracy = self.compute_accuracy()\n",
    "            print(f'Epoch {epoch + 1}/{self.epochs} - accuracy: {accuracy:.4f} - loss: {loss:.4f}')\n",
    "        \n",
    "    def test(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluates the model's accuracy on the test data.\n",
    "\n",
    "        :param X_test: The test feature matrix.\n",
    "        :type X_test: np.ndarray\n",
    "        :param y_test: The test label vector.\n",
    "        :type y_test: np.ndarray\n",
    "        :return: The accuracy of the model on the test data.\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        for i in range(len(X_test)):\n",
    "            y_pred = self.classify(X_test[i])\n",
    "            if y_pred == y_test[i]:\n",
    "                correct += 1\n",
    "        accuracy = correct / len(X_test)\n",
    "        print(f'Test set accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset and pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('Breast_cancer_data.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 6)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticated = X[X['diagnosis'] == 1]\n",
    "not_diagnosticated = X[X['diagnosis'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 6)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosticated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.80</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.26</td>\n",
       "      <td>21.88</td>\n",
       "      <td>107.50</td>\n",
       "      <td>826.8</td>\n",
       "      <td>0.11650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.83</td>\n",
       "      <td>22.33</td>\n",
       "      <td>85.26</td>\n",
       "      <td>503.2</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.09</td>\n",
       "      <td>19.83</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>0.09342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.95</td>\n",
       "      <td>20.01</td>\n",
       "      <td>114.20</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.08402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        10.80          9.71           68.77      357.6          0.09594   \n",
       "1        16.26         21.88          107.50      826.8          0.11650   \n",
       "2        12.83         22.33           85.26      503.2          0.10880   \n",
       "3        23.09         19.83          152.10     1682.0          0.09342   \n",
       "4        17.95         20.01          114.20      982.0          0.08402   \n",
       "\n",
       "   diagnosis  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split 80% of 'not_diagnosticated' data for training\n",
    "not_diagnosticated_train = not_diagnosticated.sample(frac=0.8, random_state=42)\n",
    "\n",
    "# Select the same number of samples from 'diagnosticated' as in 'not_diagnosticated_train'\n",
    "diagnosticated_train = diagnosticated.sample(n=len(not_diagnosticated_train), random_state=42)\n",
    "\n",
    "# Combine the diagnosed and not diagnosed data to create the training set\n",
    "train_data = pd.concat([not_diagnosticated_train, diagnosticated_train])\n",
    "\n",
    "# Optional: shuffle the rows to avoid an obvious sequence of classes\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.67</td>\n",
       "      <td>20.02</td>\n",
       "      <td>75.21</td>\n",
       "      <td>416.2</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.95</td>\n",
       "      <td>15.76</td>\n",
       "      <td>58.74</td>\n",
       "      <td>245.2</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.10</td>\n",
       "      <td>26.29</td>\n",
       "      <td>129.10</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>0.12150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.83</td>\n",
       "      <td>15.73</td>\n",
       "      <td>82.89</td>\n",
       "      <td>506.9</td>\n",
       "      <td>0.09040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.47</td>\n",
       "      <td>24.68</td>\n",
       "      <td>116.10</td>\n",
       "      <td>984.6</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        11.67         20.02           75.21      416.2          0.10160   \n",
       "1         8.95         15.76           58.74      245.2          0.09462   \n",
       "2        19.10         26.29          129.10     1132.0          0.12150   \n",
       "3        12.83         15.73           82.89      506.9          0.09040   \n",
       "4        17.47         24.68          116.10      984.6          0.10490   \n",
       "\n",
       "   diagnosis  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Select the remaining 20% of 'not_diagnosticated' for the test set\n",
    "not_diagnosticated_test = not_diagnosticated.drop(not_diagnosticated_train.index)\n",
    "\n",
    "# Step 2: Select the remaining samples from 'diagnosticated' for the test set\n",
    "diagnosticated_test = diagnosticated.drop(diagnosticated_train.index)\n",
    "\n",
    "# Step 3: Combine the diagnosed and not diagnosed data to create the test set\n",
    "test_data = pd.concat([not_diagnosticated_test, diagnosticated_test])\n",
    "\n",
    "# Optional: shuffle the rows to avoid an obvious sequence of classes\n",
    "test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "X_train = train_data.drop(columns='diagnosis').values\n",
    "y_train = train_data['diagnosis'].values\n",
    "X_test = test_data.drop(columns='diagnosis').values\n",
    "y_test = test_data['diagnosis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = np.mean(X_train, axis=0), np.std(X_train, axis=0)\n",
    "test_mean, test_std = np.mean(X_test, axis=0), np.std(X_test, axis=0)\n",
    "\n",
    "def normalize(X, mean, std):\n",
    "    X_norm =  (X - mean) / std\n",
    "    return X_norm\n",
    "\n",
    "X_train = normalize(X_train, train_mean, train_std)\n",
    "X_test = normalize(X_test, test_mean, test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - accuracy: 0.8971 - loss: 0.6505\n",
      "Epoch 2/100 - accuracy: 0.9000 - loss: 0.6142\n",
      "Epoch 3/100 - accuracy: 0.9000 - loss: 0.5832\n",
      "Epoch 4/100 - accuracy: 0.9000 - loss: 0.5564\n",
      "Epoch 5/100 - accuracy: 0.9000 - loss: 0.5332\n",
      "Epoch 6/100 - accuracy: 0.9000 - loss: 0.5129\n",
      "Epoch 7/100 - accuracy: 0.9000 - loss: 0.4950\n",
      "Epoch 8/100 - accuracy: 0.9000 - loss: 0.4791\n",
      "Epoch 9/100 - accuracy: 0.9000 - loss: 0.4650\n",
      "Epoch 10/100 - accuracy: 0.9029 - loss: 0.4523\n",
      "Epoch 11/100 - accuracy: 0.9029 - loss: 0.4408\n",
      "Epoch 12/100 - accuracy: 0.9029 - loss: 0.4304\n",
      "Epoch 13/100 - accuracy: 0.9029 - loss: 0.4208\n",
      "Epoch 14/100 - accuracy: 0.9029 - loss: 0.4121\n",
      "Epoch 15/100 - accuracy: 0.9029 - loss: 0.4041\n",
      "Epoch 16/100 - accuracy: 0.9029 - loss: 0.3967\n",
      "Epoch 17/100 - accuracy: 0.9029 - loss: 0.3899\n",
      "Epoch 18/100 - accuracy: 0.9029 - loss: 0.3835\n",
      "Epoch 19/100 - accuracy: 0.9029 - loss: 0.3775\n",
      "Epoch 20/100 - accuracy: 0.9029 - loss: 0.3720\n",
      "Epoch 21/100 - accuracy: 0.9029 - loss: 0.3668\n",
      "Epoch 22/100 - accuracy: 0.9029 - loss: 0.3619\n",
      "Epoch 23/100 - accuracy: 0.9029 - loss: 0.3573\n",
      "Epoch 24/100 - accuracy: 0.9029 - loss: 0.3530\n",
      "Epoch 25/100 - accuracy: 0.9029 - loss: 0.3489\n",
      "Epoch 26/100 - accuracy: 0.9029 - loss: 0.3450\n",
      "Epoch 27/100 - accuracy: 0.9029 - loss: 0.3413\n",
      "Epoch 28/100 - accuracy: 0.9029 - loss: 0.3378\n",
      "Epoch 29/100 - accuracy: 0.9029 - loss: 0.3345\n",
      "Epoch 30/100 - accuracy: 0.9029 - loss: 0.3313\n",
      "Epoch 31/100 - accuracy: 0.9029 - loss: 0.3283\n",
      "Epoch 32/100 - accuracy: 0.9029 - loss: 0.3254\n",
      "Epoch 33/100 - accuracy: 0.9029 - loss: 0.3227\n",
      "Epoch 34/100 - accuracy: 0.9029 - loss: 0.3200\n",
      "Epoch 35/100 - accuracy: 0.9029 - loss: 0.3175\n",
      "Epoch 36/100 - accuracy: 0.9059 - loss: 0.3150\n",
      "Epoch 37/100 - accuracy: 0.9088 - loss: 0.3127\n",
      "Epoch 38/100 - accuracy: 0.9088 - loss: 0.3104\n",
      "Epoch 39/100 - accuracy: 0.9088 - loss: 0.3083\n",
      "Epoch 40/100 - accuracy: 0.9059 - loss: 0.3062\n",
      "Epoch 41/100 - accuracy: 0.9059 - loss: 0.3042\n",
      "Epoch 42/100 - accuracy: 0.9059 - loss: 0.3022\n",
      "Epoch 43/100 - accuracy: 0.9059 - loss: 0.3003\n",
      "Epoch 44/100 - accuracy: 0.9088 - loss: 0.2985\n",
      "Epoch 45/100 - accuracy: 0.9088 - loss: 0.2968\n",
      "Epoch 46/100 - accuracy: 0.9088 - loss: 0.2951\n",
      "Epoch 47/100 - accuracy: 0.9088 - loss: 0.2934\n",
      "Epoch 48/100 - accuracy: 0.9088 - loss: 0.2918\n",
      "Epoch 49/100 - accuracy: 0.9088 - loss: 0.2903\n",
      "Epoch 50/100 - accuracy: 0.9088 - loss: 0.2888\n",
      "Epoch 51/100 - accuracy: 0.9088 - loss: 0.2873\n",
      "Epoch 52/100 - accuracy: 0.9088 - loss: 0.2859\n",
      "Epoch 53/100 - accuracy: 0.9088 - loss: 0.2845\n",
      "Epoch 54/100 - accuracy: 0.9088 - loss: 0.2832\n",
      "Epoch 55/100 - accuracy: 0.9088 - loss: 0.2818\n",
      "Epoch 56/100 - accuracy: 0.9088 - loss: 0.2806\n",
      "Epoch 57/100 - accuracy: 0.9088 - loss: 0.2793\n",
      "Epoch 58/100 - accuracy: 0.9088 - loss: 0.2781\n",
      "Epoch 59/100 - accuracy: 0.9088 - loss: 0.2770\n",
      "Epoch 60/100 - accuracy: 0.9088 - loss: 0.2758\n",
      "Epoch 61/100 - accuracy: 0.9088 - loss: 0.2747\n",
      "Epoch 62/100 - accuracy: 0.9088 - loss: 0.2736\n",
      "Epoch 63/100 - accuracy: 0.9088 - loss: 0.2725\n",
      "Epoch 64/100 - accuracy: 0.9088 - loss: 0.2715\n",
      "Epoch 65/100 - accuracy: 0.9059 - loss: 0.2705\n",
      "Epoch 66/100 - accuracy: 0.9059 - loss: 0.2695\n",
      "Epoch 67/100 - accuracy: 0.9059 - loss: 0.2685\n",
      "Epoch 68/100 - accuracy: 0.9059 - loss: 0.2676\n",
      "Epoch 69/100 - accuracy: 0.9059 - loss: 0.2667\n",
      "Epoch 70/100 - accuracy: 0.9059 - loss: 0.2657\n",
      "Epoch 71/100 - accuracy: 0.9059 - loss: 0.2649\n",
      "Epoch 72/100 - accuracy: 0.9059 - loss: 0.2640\n",
      "Epoch 73/100 - accuracy: 0.9059 - loss: 0.2631\n",
      "Epoch 74/100 - accuracy: 0.9059 - loss: 0.2623\n",
      "Epoch 75/100 - accuracy: 0.9059 - loss: 0.2615\n",
      "Epoch 76/100 - accuracy: 0.9029 - loss: 0.2607\n",
      "Epoch 77/100 - accuracy: 0.9059 - loss: 0.2599\n",
      "Epoch 78/100 - accuracy: 0.9059 - loss: 0.2591\n",
      "Epoch 79/100 - accuracy: 0.9059 - loss: 0.2584\n",
      "Epoch 80/100 - accuracy: 0.9059 - loss: 0.2576\n",
      "Epoch 81/100 - accuracy: 0.9059 - loss: 0.2569\n",
      "Epoch 82/100 - accuracy: 0.9059 - loss: 0.2562\n",
      "Epoch 83/100 - accuracy: 0.9059 - loss: 0.2555\n",
      "Epoch 84/100 - accuracy: 0.9059 - loss: 0.2548\n",
      "Epoch 85/100 - accuracy: 0.9118 - loss: 0.2541\n",
      "Epoch 86/100 - accuracy: 0.9118 - loss: 0.2535\n",
      "Epoch 87/100 - accuracy: 0.9118 - loss: 0.2528\n",
      "Epoch 88/100 - accuracy: 0.9118 - loss: 0.2522\n",
      "Epoch 89/100 - accuracy: 0.9118 - loss: 0.2516\n",
      "Epoch 90/100 - accuracy: 0.9118 - loss: 0.2509\n",
      "Epoch 91/100 - accuracy: 0.9118 - loss: 0.2503\n",
      "Epoch 92/100 - accuracy: 0.9118 - loss: 0.2497\n",
      "Epoch 93/100 - accuracy: 0.9118 - loss: 0.2491\n",
      "Epoch 94/100 - accuracy: 0.9118 - loss: 0.2486\n",
      "Epoch 95/100 - accuracy: 0.9118 - loss: 0.2480\n",
      "Epoch 96/100 - accuracy: 0.9118 - loss: 0.2474\n",
      "Epoch 97/100 - accuracy: 0.9118 - loss: 0.2469\n",
      "Epoch 98/100 - accuracy: 0.9118 - loss: 0.2464\n",
      "Epoch 99/100 - accuracy: 0.9118 - loss: 0.2458\n",
      "Epoch 100/100 - accuracy: 0.9118 - loss: 0.2453\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "model = LogisticRegression(X_train, y_train, epochs=100, learning_rate=0.1)\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "model.test(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
